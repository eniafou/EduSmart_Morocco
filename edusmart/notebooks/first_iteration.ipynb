{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first iteration on the first step of the pipeline: \n",
    "> generating a general QCM about a specific course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/eniafou/dev/EduSmart_Morocco/edusmart')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_76197/2846649666.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  ex_exo = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "ex_exo = \"\"\"\n",
    "\\section*{Exercice 6}\n",
    "\n",
    "Montrer que : \n",
    "\\[\n",
    "\\forall (a, b) \\in \\mathbb{R}^2 : a^2 + b^2 = 1 \\implies |a + b| \\leq \\sqrt{2}\n",
    "\\]\n",
    "\n",
    "\\textbf{Solution:} \n",
    "\n",
    "1) Supposons que $a^2 + b^2 = 1$.\n",
    "\n",
    "Or on sait que $\\forall (a, b) \\in \\mathbb{R}: (a - b)^2 \\geq 0$\n",
    "\n",
    "Donc : $a^2 - 2ab + b^2 \\geq 0$ et puisque $a^2 + b^2 = 1$ alors : \n",
    "$1 - 2ab \\geq 0$. Donc $2ab \\leq 1$ et $a^2 + b^2 = 1$.\n",
    "\n",
    "Par suite : $a^2 + b^2 + 2ab \\leq 2 \\implies (a + b)^2 \\leq 2$\n",
    "\n",
    "\\[\n",
    "\\therefore \\sqrt{(a + b)^2} \\leq \\sqrt{2} \\implies |a + b| \\leq \\sqrt{2}\n",
    "\\]\n",
    "\n",
    "Or on sait que $a^2 \\in \\mathbb{R}^+$ donc $a^2 \\in \\mathbb{R}^* \\cap \\mathbb{R}^-$ donc $a^2 = 0$ donc $a = 0$.\n",
    "\n",
    "Et puisque $a^2 + b^2 = 0$ alors $b = 0$.\n",
    "\n",
    "\\textbf{2)} Résolution du système d'équations.\n",
    "\n",
    "\n",
    "\n",
    "\\section*{Exercice 11}\n",
    "\n",
    "Montrer que pour tout $x \\in \\mathbb{R}: |x - 1| \\leq x^2 - x + 1$.\n",
    "\n",
    "\\textbf{Solution:} Soit $x \\in \\mathbb{R}$. Nous distinguons deux cas :\n",
    "\n",
    "1. Si $x > 1$, alors $|x - 1| = x - 1$.\n",
    "2. Si $x < 1$, alors $|x - 1| = -(x - 1)$.\n",
    "\n",
    "Dans tous les cas, $x^2 - x + 1 \\geq |x - 1|$.\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\\textbf{Exercise 5:}\n",
    "1) Montrer que:\n",
    "\\begin{equation*}\n",
    "\\forall (a,b) \\in \\mathbb{R}^2: \\ a^2 + b^2 = 0 \\implies a = 0 \\text{ et } b = 0\n",
    "\\end{equation*}\n",
    "\n",
    "2) $x \\in \\mathbb{R}^+$ et $y \\in \\mathbb{R}^+$. Montrer que:\n",
    "\\begin{equation*}\n",
    "x + y + 2 = 2\\sqrt{x} + 2\\sqrt{y} \\implies x = y = 1\n",
    "\\end{equation*}\n",
    "\n",
    "Solution:\n",
    "1)\n",
    "\\begin{align*}\n",
    "a^2 + b^2 = 0 &\\implies a^2 = -b^2 \\\\\n",
    "&\\implies a^2 \\in \\mathbb{R}^-\n",
    "\\end{align*}\n",
    "Or on sait que $a^2 \\in \\mathbb{R}^+$ donc $a^2 \\in \\mathbb{R}^+ \\cap \\mathbb{R}^-$ donc $a^2 = 0$\n",
    "donc $a = 0$\n",
    "\n",
    "Et puisque $a^2 + b^2 = 0$ alors $b = 0$\n",
    "\n",
    "2)\n",
    "\\begin{align*}\n",
    "x + y + 2 = 2\\sqrt{x} + 2\\sqrt{y} &\\implies x - 2\\sqrt{x} + 1 + y - 2\\sqrt{y} + 1 = 0 \\\\\n",
    "&\\implies (\\sqrt{x} - 1)^2 + (\\sqrt{y} - 1)^2 = 0 \\\\\n",
    "&\\implies \\sqrt{x} - 1 = 0 \\text{ et } \\sqrt{y} - 1 = 0 \\text{ d'après 1)} \\\\\n",
    "&\\implies \\sqrt{x} = 1 \\text{ et } \\sqrt{y} = 1 \\\\\n",
    "&\\implies x = 1 \\text{ et } y = 1\n",
    "\\end{align*}\n",
    "\n",
    "Donc: $x + y + 2 = 2\\sqrt{x} + 2\\sqrt{y} \\implies x = y = 1$\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_QCM_GENERAL_SCI = \"\"\"\n",
    "Vous êtes une intelligence artificielle chargée de générer des questions à choix multiple (QCM) en format LaTeX basées sur le cours, le niveau scolaire et\\\n",
    "les exercices d'exemple que je vous fournirai. Ne suivez pas exactement ces exemples de questions car elles ne sont pas nécessairement des questions QCM. \n",
    "Toutes les questions doivent être au même niveau de difficulté, que je spécifierai. Les questions, les options\\\n",
    "et la réponse correcte doivent être structurées comme suit et renvoyées sous la forme JSON:\n",
    "{{\n",
    "  \"question\": \"Le texte de la question en LaTeX\",\n",
    "  \"options\": [\n",
    "    \"A - Option 1 en LaTeX\",\n",
    "    \"B - Option 2 en LaTeX\",\n",
    "    \"C - Option 3 en LaTeX\",\n",
    "    \"D - Option 4 en LaTeX\"\n",
    "  ],\n",
    "  \"correct_answer\": \"La bonne réponse, par exemple A\"\n",
    "}}\n",
    "Respectez les consignes suivantes :\n",
    "Les questions doivent être conformes au niveau de difficulté spécifié (Facile, Moyen ou Difficile).\n",
    "Chaque question doit comporter des propositions plausibles, y compris des distracteurs basés sur des idées fausses courantes ou des erreurs typiques liées\\\n",
    "au sujet.\n",
    "Les questions doivent être clairement formulées, et les expressions mathématiques en LaTeX doivent être correctes et lisibles.\n",
    "Les questions doivent couvrir différents types de raisonnement : résolution d’équations, compréhension de propositions, raisonnement logique ou application\\\n",
    "de formules.\n",
    "La réponse correcte doit être clairement identifiable parmi les options.\n",
    "Ne fournissez aucune explication, uniquement les structures de dictionnaire des questions, telles que définies ci-dessus.\n",
    "\n",
    "\n",
    "Générez {} questions en fonction des spécifications fournies ci-dessous:\n",
    "\n",
    "Niveau scolaire : {}\n",
    "Matière: {}\n",
    "Cours: {}\n",
    "Niveau de difficulté : {}\n",
    "Exemple d'exercices: \n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PROMPT_QCM_GENERAL_SCI.format(5,\"1ere année bac sciences math Maroc\", \"Mathématiques\", \"Notion de logique\", \"Moyen\", ex_exo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": PROMPT_QCM_GENERAL_SCI.format(5,\"1ere année bac sciences math Maroc\", \"Mathématiques\", \"Notion de logique\", \"Moyen\", ex_exo)}\n",
    "    ],\n",
    "    response_format = { \"type\": \"json_object\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"questions\": [\\n    {\\n      \"question\": \"Montrer que pour tout $(a, b) \\\\\\\\in \\\\\\\\mathbb{R}^2$, si $a^2 + b^2 = 1$, alors $|a - b| \\\\\\\\leq \\\\\\\\sqrt{2}$.\",\\n      \"options\": [\\n        \"A - $|a - b| \\\\\\\\geq 0$\",\\n        \"B - $|a - b| = 1$\",\\n        \"C - $|a - b| \\\\\\\\leq \\\\\\\\sqrt{2}$\",\\n        \"D - $|a - b| \\\\\\\\leq 1$\"\\n      ],\\n      \"correct_answer\": \"C\"\\n    },\\n    {\\n      \"question\": \"Si $x, y \\\\\\\\in \\\\\\\\mathbb{R}^+$, lequel des énoncés suivants est vrai si $x + y = 2$ ?\",\\n      \"options\": [\\n        \"A - $\\\\\\\\sqrt{x} + \\\\\\\\sqrt{y} \\\\\\\\leq 2$\",\\n        \"B - $\\\\\\\\sqrt{x + y} = 1$\",\\n        \"C - $\\\\\\\\sqrt{x} - \\\\\\\\sqrt{y} = 0$\",\\n        \"D - $|x - y| \\\\\\\\leq 2$\"\\n      ],\\n      \"correct_answer\": \"A\"\\n    },\\n    {\\n      \"question\": \"Pour tout $x \\\\\\\\in \\\\\\\\mathbb{R}$, montrez que $|x + 1| \\\\\\\\geq 1$ si $x \\\\\\\\leq 0$.\",\\n      \"options\": [\\n        \"A - Cela est faux pour $x = -2$\",\\n        \"B - Cela est vrai seulement pour $x = 0$\",\\n        \"C - Cela est vrai pour tout $x < 0$\",\\n        \"D - Cela est vrai pour tout $x > 0$\"\\n      ],\\n      \"correct_answer\": \"C\"\\n    },\\n    {\\n      \"question\": \"Si $x \\\\\\\\in \\\\\\\\mathbb{R}$, quel est le meilleur moyen d\\'exprimer $|x - 3| < 5$ en termes d\\'inégalités ?\",\\n      \"options\": [\\n        \"A - $-5 < x < 8$\",\\n        \"B - $-2 < x < 8$\",\\n        \"C - $3 - 5 < x < 3 + 5$\",\\n        \"D - $0 < x < 6$\"\\n      ],\\n      \"correct_answer\": \"C\"\\n    },\\n    {\\n      \"question\": \"Montrez que pour tout $x \\\\\\\\in \\\\\\\\mathbb{R}$, $|x^2 - 1| \\\\\\\\leq |x - 1| \\\\\\\\cdot |x + 1|$. Quelle est la bonne formulation ?\",\\n      \"options\": [\\n        \"A - C\\'est faux car $|x - 1| < 0$\",\\n        \"B - C\\'est vrai seulement pour $x = 0$\",\\n        \"C - C\\'est une inégalité toujours vraie pour $x \\\\\\\\in \\\\\\\\mathbb{R}$\",\\n        \"D - C\\'est vrai seulement pour $x > 1$\"\\n      ],\\n      \"correct_answer\": \"C\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylatex import Document, Section, Subsection, Command, Itemize, NoEscape\n",
    "from pylatex.utils import escape_latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def generate_quiz_pdf(data, output_file=\"quiz.pdf\"):\n",
    "#     # Initialize the document\n",
    "#     doc = Document()\n",
    "\n",
    "#     # Add a title\n",
    "#     doc.preamble.append(Command(\"title\", \"Quiz\"))\n",
    "#     doc.preamble.append(Command(\"author\", \"Generated Quiz\"))\n",
    "#     doc.preamble.append(Command(\"date\", NoEscape(r\"\\today\")))\n",
    "#     doc.append(NoEscape(r\"\\maketitle\"))\n",
    "\n",
    "#     # Loop through questions and add to the document\n",
    "#     for idx, item in enumerate(data['questions']):\n",
    "#         question = item['question']\n",
    "#         options = item['options']\n",
    "#         correct_answer = item['correct_answer']\n",
    "\n",
    "#         # Add question as a subsection\n",
    "#         with doc.create(Section(f\"Question {idx + 1}\")):\n",
    "#             doc.append(NoEscape(question))  # Use NoEscape to handle LaTeX\n",
    "#             doc.append(\"\\n\\n\")\n",
    "\n",
    "#             # Add options as an itemized list\n",
    "#             with doc.create(Itemize()) as itemize:\n",
    "#                 for option in options:\n",
    "#                     itemize.add_item(NoEscape(option))\n",
    "\n",
    "#             # Uncomment this line to include correct answers in the PDF\n",
    "#             # doc.append(NoEscape(f\"\\n\\n\\\\textbf{{Correct Answer: {escape_latex(correct_answer)}}}\"))\n",
    "#     print(\"Ia m\")\n",
    "#     # Generate the PDF\n",
    "#     doc.generate_pdf(output_file, compiler='pdflatex',clean_tex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_quiz_pdf(data, output_file=\"quiz.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# Path to the uploaded PDF file\n",
    "pdf_path = '/mnt/data/seance-1-1-1-notion-de-logique-partie-1-cours-3.pdf'\n",
    "\n",
    "# Convert PDF pages to images\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# Perform OCR on each page and store text\n",
    "ocr_text = [pytesseract.image_to_string(image, lang='eng+fra') for image in images]\n",
    "\n",
    "# Combine all extracted text into one string\n",
    "full_text = \"\\n\\n\".join(ocr_text)\n",
    "\n",
    "# Save the extracted text for review\n",
    "text_file_path = \"/mnt/data/extracted_text.txt\"\n",
    "with open(text_file_path, \"w\") as text_file:\n",
    "    text_file.write(full_text)\n",
    "\n",
    "text_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = []\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(image, lang='eng+fra')\n",
    "        extracted_text.append(text)\n",
    "    except Exception as e:\n",
    "        extracted_text.append(f\"Error processing page {i+1}: {str(e)}\")\n",
    "\n",
    "# Combine all extracted text into one string\n",
    "full_text_incremental = \"\\n\\n\".join(extracted_text)\n",
    "\n",
    "# Save the extracted text for review\n",
    "text_file_path_incremental = \"/mnt/data/extracted_text_incremental.txt\"\n",
    "with open(text_file_path_incremental, \"w\") as text_file:\n",
    "    text_file.write(full_text_incremental)\n",
    "\n",
    "text_file_path_incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert plain text to a LaTeX document structure\n",
    "def text_to_latex(text):\n",
    "    latex_document = r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{amsmath, amssymb}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\"\"\" + text.replace(\"\\n\", \"\\n\\n\") + r\"\"\"\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    return latex_document\n",
    "\n",
    "# Convert extracted text to LaTeX\n",
    "latex_code = text_to_latex(full_text_incremental)\n",
    "\n",
    "# Save the LaTeX code to a file\n",
    "latex_file_path = \"/mnt/data/converted_to_latex.tex\"\n",
    "with open(latex_file_path, \"w\") as latex_file:\n",
    "    latex_file.write(latex_code)\n",
    "\n",
    "latex_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'data': [{'sous_cours_name': 'Lois logiques et raisonnements', 'content': [{'question': 'La proposition suivante est une tautologie : $P \\\\implies (Q \\\\implies P)$ ?', 'options': ['A - Vrai', 'B - Faux', 'C - Cela dépend des valeurs de $P$ et $Q$', 'D - Cela dépend uniquement de $Q$'], 'correct_answer': 'A'}, {'question': 'Les lois de Morgan stipulent que : $(P \\\\land Q) \\\\iff (\\\\neg P \\\\lor \\\\neg Q)$ est vrai ?', 'options': ['A - Vrai', 'B - Faux', 'C - Cela dépend des valeurs de $P$ et $Q$', 'D - Cela est vrai uniquement pour des propositions fausses'], 'correct_answer': 'A'}, {'question': \"La contraposée de l'implication $P \\\\implies Q$ est : $\\\\neg Q \\\\implies \\\\neg P$ ?\", 'options': ['A - Vrai', 'B - Faux', \"C - Cela s'applique uniquement aux lois logiques\", 'D - Cela dépend des valeurs de $P$ et $Q$'], 'correct_answer': 'A'}]}, {'sous_cours_name': 'Opérations sur les propositions', 'content': [{'question': 'La négation de la proposition $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 \\\\geq 0$ est :', 'options': ['A - $(\\\\exists x \\\\in \\\\mathbb{R}); x^2 < 0$', 'B - $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 < 0$', 'C - $(\\\\exists x \\\\in \\\\mathbb{R}); x^2 \\\\geq 0$', 'D - $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 > 0$'], 'correct_answer': 'A'}, {'question': 'Quelle est la forme correcte de la négation de la proposition $P: (\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x = 2$ ?', 'options': ['A - $(\\\\forall x \\\\in \\\\mathbb{R}); \\\\sin x \\\\neq 2$', 'B - $(\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x \\\\neq 2$', 'C - $(\\\\forall x \\\\in \\\\mathbb{R}); \\\\sin x = 2$', 'D - $(\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x = 2$'], 'correct_answer': 'A'}, {'question': 'La proposition $Q: (\\\\forall n \\\\in \\\\mathbb{N}); 2n$ est pair, est :', 'options': ['A - Vraie', 'B - Fausse, car $2n + 1$ est impair', 'C - Fausse, car $2n + 1$ est pair', 'D - Toujours vraie car $n$ est un nombre naturel'], 'correct_answer': 'A'}]}, {'sous_cours_name': 'Proposition - fonction propositionnelle', 'content': [{'question': 'Soit la proposition suivante : $P : \\\\sqrt[3]{5} = \\\\frac{5}{\\\\sqrt[3]{25}}$. Quelle est la valeur de vérité de $P$ ?', 'options': ['A - Vraie', 'B - Fausse', 'C - Indéterminée', 'D - Aucune de ces réponses'], 'correct_answer': 'B'}, {'question': 'Considérons la fonction propositionnelle $P(x, y) : (x, y) \\\\in \\\\mathbb{R}^2; 2x - 3y = 7$. Quelle est la valeur de $y$ pour $P(2, y)$ ?', 'options': ['A - $y = -\\\\frac{1}{3}$', 'B - $y = \\\\frac{13}{3}$', 'C - $y = 3$', 'D - $y = 1$'], 'correct_answer': 'B'}, {'question': 'Pour la fonction propositionnelle $D(x) : x \\\\in \\\\mathbb{R}; x^2 + x + 6 \\\\geq 0$, quel ensemble de valeurs de $x$ assure que $D(x)$ est vraie ?', 'options': ['A - $x \\\\in \\\\mathbb{R}$', 'B - $x \\\\geq -1$', 'C - $x \\\\in \\\\emptyset$', 'D - $x \\\\in (-\\\\infty, -3] \\\\cup [-2, +\\\\infty)$'], 'correct_answer': 'A'}]}, {'sous_cours_name': 'Quantificateurs', 'content': [{'question': 'Soit $E = \\\\mathbb{R}$. Quelle est la valeur de vérité de la proposition $Q: (\\\\exists x \\\\in E); x^2 + x + 1 = 0$?', 'options': ['A - Vraie', 'B - Fausse', 'C - Indéterminée', 'D - Toujours vraie'], 'correct_answer': 'B'}, {'question': \"Pour l'ensemble $E = \\\\mathbb{R}$, que peut-on dire de la proposition $P: (\\\\forall x \\\\in E); (x^2 + 1 > 0)$?\", 'options': ['A - Elle est fausse pour $x = 0$', 'B - Elle est vraie pour tous les $x \\\\in E$', 'C - Elle est vraie pour tous les $x \\\\in \\\\mathbb{N}$', 'D - Elle est indéterminée'], 'correct_answer': 'B'}, {'question': 'La proposition $Q: (\\\\exists! x \\\\in \\\\mathbb{R}); x^2 + 1 = 0$ est-elle vraie?', 'options': ['A - Oui, car il existe un unique $x$', \"B - Non, car il n'existe pas de $x$\", 'C - Oui, mais il y a plusieurs $x$', 'D - Non, car tous les $x$ vérifient $x^2 + 1 = 0$'], 'correct_answer': 'B'}]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sous_cours_name': 'Opérations sur les propositions',\n",
       " 'content': [{'question': 'La négation de la proposition $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 \\\\geq 0$ est :',\n",
       "   'options': ['A - $(\\\\exists x \\\\in \\\\mathbb{R}); x^2 < 0$',\n",
       "    'B - $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 < 0$',\n",
       "    'C - $(\\\\exists x \\\\in \\\\mathbb{R}); x^2 \\\\geq 0$',\n",
       "    'D - $(\\\\forall x \\\\in \\\\mathbb{R}); x^2 > 0$'],\n",
       "   'correct_answer': 'A'},\n",
       "  {'question': 'Quelle est la forme correcte de la négation de la proposition $P: (\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x = 2$ ?',\n",
       "   'options': ['A - $(\\\\forall x \\\\in \\\\mathbb{R}); \\\\sin x \\\\neq 2$',\n",
       "    'B - $(\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x \\\\neq 2$',\n",
       "    'C - $(\\\\forall x \\\\in \\\\mathbb{R}); \\\\sin x = 2$',\n",
       "    'D - $(\\\\exists x \\\\in \\\\mathbb{R}); \\\\sin x = 2$'],\n",
       "   'correct_answer': 'A'},\n",
       "  {'question': 'La proposition $Q: (\\\\forall n \\\\in \\\\mathbb{N}); 2n$ est pair, est :',\n",
       "   'options': ['A - Vraie',\n",
       "    'B - Fausse, car $2n + 1$ est impair',\n",
       "    'C - Fausse, car $2n + 1$ est pair',\n",
       "    'D - Toujours vraie car $n$ est un nombre naturel'],\n",
       "   'correct_answer': 'A'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sous_cours_name': 'Lois logiques et raisonnements',\n",
       " 'content': [{'question': 'La proposition suivante est une tautologie : $P \\\\implies (Q \\\\implies P)$ ?',\n",
       "   'options': ['A - Vrai',\n",
       "    'B - Faux',\n",
       "    'C - Cela dépend des valeurs de $P$ et $Q$',\n",
       "    'D - Cela dépend uniquement de $Q$'],\n",
       "   'correct_answer': 'A'},\n",
       "  {'question': 'Les lois de Morgan stipulent que : $(P \\\\land Q) \\\\iff (\\\\neg P \\\\lor \\\\neg Q)$ est vrai ?',\n",
       "   'options': ['A - Vrai',\n",
       "    'B - Faux',\n",
       "    'C - Cela dépend des valeurs de $P$ et $Q$',\n",
       "    'D - Cela est vrai uniquement pour des propositions fausses'],\n",
       "   'correct_answer': 'A'},\n",
       "  {'question': \"La contraposée de l'implication $P \\\\implies Q$ est : $\\\\neg Q \\\\implies \\\\neg P$ ?\",\n",
       "   'options': ['A - Vrai',\n",
       "    'B - Faux',\n",
       "    \"C - Cela s'applique uniquement aux lois logiques\",\n",
       "    'D - Cela dépend des valeurs de $P$ et $Q$'],\n",
       "   'correct_answer': 'A'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customized_cours(general_qcm_submition):\n",
    "    \"\"\"\n",
    "    general_qcm_submition has 3 keys:\n",
    "    - answers\n",
    "    - qcm\n",
    "    - meta (contains: the level, year, branch, subject, lesson)\n",
    "\n",
    "    returns:\n",
    "    out = {\"data\" = [\n",
    "        {\"sub_title\": , \"content\": {}},\n",
    "    ]}\n",
    "    \"\"\"\n",
    "    meta =  mapping_front_back_meta_form(general_qcm_submition[\"meta\"])\n",
    "    data = {\"data\":[]}\n",
    "    full_path_cours = cv.ROOT_DATABASE_PATH + meta[\"level\"] + \"/\" + meta[\"year\"] + \"/\" + meta[\"branch\"] + \"/\" + meta[\"subject\"] + \"/\" + meta[\"lesson\"]\n",
    "    \n",
    "    lacunes = compare_answers(general_qcm_submition)\n",
    "    set_exo = get_similar_exo_qcm(meta[\"level\"], meta[\"year\"], meta[\"branch\"], meta[\"subject\"], meta[\"lesson\"], lacunes)\n",
    "    for item in lacunes:\n",
    "        sous_cours = load_sous_cours(full_path_cours + \"/cours/\" + item[\"sous_cours_name\"] + \".txt\")\n",
    "        prompt = pmt.PROMPT_QCM_GENERAL_SCI.format(f\"{cn.level_mapping[meta[\"level\"]]} {cn.year_mapping[meta[\"year\"]]} {cn.branch_mapping[meta[\"branch\"]]} Maroc\", cn.subject_mapping[meta[\"subject\"]], cn.lesson_mapping[meta[\"lesson\"]],sous_cours,item[\"question\"])\n",
    "        response = generate_from_prompt_json(prompt)\n",
    "        content = json.loads(response)[\"data\"]\n",
    "        sous_proposed_cours = {\"sub_title\": item[\"sous_cours_name\"], \"content\": content}\n",
    "        data[\"data\"].append(sous_proposed_cours)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
